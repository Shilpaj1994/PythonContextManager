{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tshHP0A3icf2"
      },
      "source": [
        "## Problem Statement\n",
        "For this project you have 4 files containing information about persons.\n",
        "\n",
        "The files are:\n",
        "\n",
        "- `personal_info.csv` - personal information such as name, gender, etc. (one row per person)\n",
        "- `vehicles.csv` - what vehicle people own (one row per person)\n",
        "- `employment.csv` - where a person is employed (one row per person)\n",
        "- `update_status.csv` - when the person's data was created and last updated\n",
        "Each file contains a key, SSN, which uniquely identifies a person.\n",
        "\n",
        "This key is present in all four files.\n",
        "\n",
        "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
        "\n",
        "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHawjUhmihHt"
      },
      "source": [
        "### Goal 1\n",
        "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
        "\n",
        "For now these four iterators are just separate, independent iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTHAxdpviZc9"
      },
      "source": [
        "# Standard Library Imports\n",
        "import csv\n",
        "import datetime\n",
        "from collections import namedtuple, Counter\n",
        "from itertools import islice\n",
        "from collections.abc import Iterator, Iterable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqwyy2n1iffg"
      },
      "source": [
        "# NamedTuples used for casting data\n",
        "SSN = namedtuple('SSN', \"AreaNumber GroupNumber SerialNumber\")\n",
        "Date = namedtuple('Date', \"month day year\")\n",
        "DateTime = namedtuple('DateTime', \"Year Month Day Hour Minute Second\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU4WuB-LrRBw"
      },
      "source": [
        "# Casted Data Format\n",
        "personal_info_data_types = ['SSN', 'STRING', 'STRING', 'STRING', 'STRING']\n",
        "vehicle_info_data_types = ['SSN', 'STRING', 'STRING', 'INT']\n",
        "employment_info_data_types = ['STRING', 'STRING', 'STRING', 'SSN']\n",
        "update_info_data_types = ['SSN', 'DateTime', 'DateTime']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGJ6axw8FUQH"
      },
      "source": [
        "class DataIterator:\n",
        "    def __init__(self, fname, data_category, expected_data_types):\n",
        "        self._fname = fname\n",
        "        self._f = None\n",
        "        self.headers = None\n",
        "        self._data_category = data_category\n",
        "        self._namedtuple = None\n",
        "        self.expected_data_types = expected_data_types\n",
        "\n",
        "        # Read and cast the data in proper namedtuple format\n",
        "        self._f = DataIterator.read_file(self._fname)\n",
        "        self.headers = next(self._f)\n",
        "        self._namedtuple = namedtuple(self._data_category, self.headers)\n",
        "        self.casted_data = (DataIterator.cast_row(self._namedtuple, row, self.expected_data_types) for row in self._f)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        return next(self.casted_data)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
        "        return False\n",
        "    \n",
        "    @staticmethod\n",
        "    def read_file(filename):\n",
        "        \"\"\"\n",
        "        Function to read the csv file\n",
        "        :param filename: Name of the file\n",
        "        :return: Row from the file\n",
        "        \"\"\"\n",
        "        with open(filename) as file:\n",
        "            rows = csv.reader(file, delimiter=',', quotechar='\"')\n",
        "            yield from rows\n",
        "\n",
        "    @staticmethod\n",
        "    def cast_row(named_tuple, data_row, data_type):\n",
        "        \"\"\"\n",
        "        Function to return the casted value of the data row\n",
        "        :param named_tuple: Instance of namedtuple in which the output is expected\n",
        "        :param data_row: Input data row\n",
        "        :param data_type: Expected data type\n",
        "        :return: Data row in the converted format\n",
        "        \"\"\"\n",
        "        casted_data = (DataIterator.cast(data_type, value) for data_type, value in zip(data_type, data_row))\n",
        "\n",
        "        _data = named_tuple(*casted_data)\n",
        "        return _data\n",
        "\n",
        "    @staticmethod\n",
        "    def cast(data_type, value):\n",
        "        \"\"\"\n",
        "        Function to cast appropriate data type for the input value\n",
        "        :param data_type: Expected data type\n",
        "        :param value: Input value\n",
        "        :return: Converted value in the data_type\n",
        "        \"\"\"\n",
        "        if data_type == 'STRING':\n",
        "            return str(value)\n",
        "        elif data_type == 'INT':\n",
        "            return int(value)\n",
        "        elif data_type == 'DATE':\n",
        "            value = value.split('/')\n",
        "            return Date(*value)\n",
        "        elif data_type == 'SSN':\n",
        "            value = value.split('-')\n",
        "            return SSN(*value)\n",
        "        elif data_type == 'DateTime':\n",
        "            _date, _time = value.split('T')\n",
        "            _date = _date.split('-')\n",
        "            _time_data, _ = _time.split('Z')\n",
        "            _time = _time_data.split(':')\n",
        "            _datetime_date = _date + _time\n",
        "            _format = [int(element) for element in _datetime_date]\n",
        "            return datetime.datetime(*_format)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44RGUVcKOm2U",
        "outputId": "61d3df93-873a-4b2e-d908-4efc63c3e55e"
      },
      "source": [
        "# Create Iterator for all four files\n",
        "personal_info_iterator = DataIterator('personal_info.csv', 'PersonalInfo', personal_info_data_types)\n",
        "vehicle_info_iterator = DataIterator('vehicles.csv', 'VehicleInfo', vehicle_info_data_types)\n",
        "employment_info_iterator = DataIterator('employment.csv', 'EmploymentInfo', employment_info_data_types)\n",
        "update_info_iterator = DataIterator('update_status.csv', 'UpdateInfo', update_info_data_types)\n",
        "\n",
        "# Check if instances are Iterators\n",
        "print(f\"Is `personal_info_iterator` an Iterator: {isinstance(personal_info_iterator, Iterator)}\")\n",
        "print(f\"Is `vehicle_info_iterator` an Iterator: {isinstance(vehicle_info_iterator, Iterator)}\")\n",
        "print(f\"Is `employment_info_iterator` an Iterator: {isinstance(employment_info_iterator, Iterator)}\")\n",
        "print(f\"Is `update_info_iterator` an Iterator: {isinstance(update_info_iterator, Iterator)}\")\n",
        "print(\"  \")\n",
        "\n",
        "# Print Sample Data from each Iterator\n",
        "[print(row) for row in islice(personal_info_iterator, 5)]\n",
        "print(\"  \")\n",
        "[print(row) for row in islice(vehicle_info_iterator, 5)]\n",
        "print(\"  \")\n",
        "[print(row) for row in islice(employment_info_iterator, 5)]\n",
        "print(\"  \")\n",
        "[print(row) for row in islice(update_info_iterator, 5)]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is `personal_info_iterator` an Iterator: True\n",
            "Is `vehicle_info_iterator` an Iterator: True\n",
            "Is `employment_info_iterator` an Iterator: True\n",
            "Is `update_info_iterator` an Iterator: True\n",
            "  \n",
            "PersonalInfo(ssn=SSN(AreaNumber='100', GroupNumber='53', SerialNumber='9824'), first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
            "PersonalInfo(ssn=SSN(AreaNumber='101', GroupNumber='71', SerialNumber='4702'), first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
            "PersonalInfo(ssn=SSN(AreaNumber='101', GroupNumber='84', SerialNumber='0356'), first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n",
            "PersonalInfo(ssn=SSN(AreaNumber='104', GroupNumber='22', SerialNumber='0928'), first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi')\n",
            "PersonalInfo(ssn=SSN(AreaNumber='104', GroupNumber='84', SerialNumber='7144'), first_name='Claudianus', last_name='Brixey', gender='Male', language='Afrikaans')\n",
            "  \n",
            "VehicleInfo(ssn=SSN(AreaNumber='100', GroupNumber='53', SerialNumber='9824'), vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
            "VehicleInfo(ssn=SSN(AreaNumber='101', GroupNumber='71', SerialNumber='4702'), vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
            "VehicleInfo(ssn=SSN(AreaNumber='101', GroupNumber='84', SerialNumber='0356'), vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n",
            "VehicleInfo(ssn=SSN(AreaNumber='104', GroupNumber='22', SerialNumber='0928'), vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000)\n",
            "VehicleInfo(ssn=SSN(AreaNumber='104', GroupNumber='84', SerialNumber='7144'), vehicle_make='Ford', vehicle_model='Crown Victoria', model_year=2008)\n",
            "  \n",
            "EmploymentInfo(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn=SSN(AreaNumber='100', GroupNumber='53', SerialNumber='9824'))\n",
            "EmploymentInfo(employer='Nicolas and Sons', department='Sales', employee_id='41-6841359', ssn=SSN(AreaNumber='101', GroupNumber='71', SerialNumber='4702'))\n",
            "EmploymentInfo(employer='Connelly Group', department='Research and Development', employee_id='98-7952860', ssn=SSN(AreaNumber='101', GroupNumber='84', SerialNumber='0356'))\n",
            "EmploymentInfo(employer='Upton LLC', department='Marketing', employee_id='56-9817552', ssn=SSN(AreaNumber='104', GroupNumber='22', SerialNumber='0928'))\n",
            "EmploymentInfo(employer='Zemlak-Olson', department='Business Development', employee_id='46-2886707', ssn=SSN(AreaNumber='104', GroupNumber='84', SerialNumber='7144'))\n",
            "  \n",
            "UpdateInfo(ssn=SSN(AreaNumber='100', GroupNumber='53', SerialNumber='9824'), last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30))\n",
            "UpdateInfo(ssn=SSN(AreaNumber='101', GroupNumber='71', SerialNumber='4702'), last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), created=datetime.datetime(2016, 1, 27, 4, 32, 57))\n",
            "UpdateInfo(ssn=SSN(AreaNumber='101', GroupNumber='84', SerialNumber='0356'), last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), created=datetime.datetime(2016, 9, 21, 23, 4, 7))\n",
            "UpdateInfo(ssn=SSN(AreaNumber='104', GroupNumber='22', SerialNumber='0928'), last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29), created=datetime.datetime(2016, 4, 15, 11, 37, 17))\n",
            "UpdateInfo(ssn=SSN(AreaNumber='104', GroupNumber='84', SerialNumber='7144'), last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33), created=datetime.datetime(2016, 3, 15, 14, 7, 57))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXD513CulgdW"
      },
      "source": [
        "---\n",
        "\n",
        "### Goal 2\n",
        "Create a single iterable that combines all the columns from all the iterators.\n",
        "\n",
        "The iterable should yield named tuples containing all the columns. Make sure that the SSN's across the files match!\n",
        "\n",
        "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
        "\n",
        "Make sure the SSN is not repeated 4 times - one time per row is enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTpkSiFSuU6J",
        "outputId": "6a331346-6b36-4533-bab8-15d67b33f763"
      },
      "source": [
        "# Create Iterator for all four files\n",
        "personal_info_iterator = DataIterator('personal_info.csv', 'PersonalInfo', personal_info_data_types)\n",
        "vehicle_info_iterator = DataIterator('vehicles.csv', 'VehicleInfo', vehicle_info_data_types)\n",
        "employment_info_iterator = DataIterator('employment.csv', 'EmploymentInfo', employment_info_data_types)\n",
        "update_info_iterator = DataIterator('update_status.csv', 'UpdateInfo', update_info_data_types)\n",
        "\n",
        "# Extract each row from the Iterator\n",
        "combined_fields = []\n",
        "row1 = next(personal_info_iterator)\n",
        "row2 = next(vehicle_info_iterator)\n",
        "row3 = next(employment_info_iterator)\n",
        "row4 = next(update_info_iterator)\n",
        "\n",
        "# Collect all the field names from the namedtuple data\n",
        "[combined_fields.append(field) for field in row1._fields]\n",
        "[combined_fields.append(field) for field in row2._fields]\n",
        "[combined_fields.append(field) for field in row3._fields]\n",
        "[combined_fields.append(field) for field in row4._fields]\n",
        "\n",
        "# Remove the repeated fileds \n",
        "combined_fields = set(combined_fields)\n",
        "print(combined_fields)\n",
        "\n",
        "# Create NamedTuple for Combined Data\n",
        "CombinedData = namedtuple('CombinedData', combined_fields)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'last_name', 'language', 'employer', 'last_updated', 'gender', 'department', 'model_year', 'employee_id', 'ssn', 'vehicle_make', 'created', 'first_name', 'vehicle_model'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZPLzjLmPuP0",
        "outputId": "2157e2a0-1d43-4c76-9963-5ef1a37dcf4d"
      },
      "source": [
        "# Create Iterator for all four files\n",
        "with DataIterator('personal_info.csv', 'PersonalInfo', personal_info_data_types) as personal_info_iterator:\n",
        "    with DataIterator('vehicles.csv', 'VehicleInfo', vehicle_info_data_types) as vehicle_info_iterator:\n",
        "        with DataIterator('employment.csv', 'EmploymentInfo', employment_info_data_types) as employment_info_iterator:\n",
        "            with DataIterator('update_status.csv', 'UpdateInfo', update_info_data_types) as update_info_iterator:\n",
        "                # List to store the combined data\n",
        "                combined_data = []\n",
        "\n",
        "                # Iterate over each row in all the data\n",
        "                for personal_data, vehicle_data, employment_data, update_data in zip(personal_info_iterator, vehicle_info_iterator, employment_info_iterator, update_info_iterator):\n",
        "                    # Dictionary to store all the data\n",
        "                    temp = dict()\n",
        "\n",
        "                    # SSN of a person from personal information\n",
        "                    _ssn = personal_data.ssn\n",
        "\n",
        "                    # Store each type of a data in a separate temporary dictionary\n",
        "                    temp_1 = {field: getattr(personal_data, field) for field in personal_data._fields}\n",
        "                    temp_2 = {field: getattr(vehicle_data, field) for field in vehicle_data._fields if vehicle_data.ssn == _ssn}\n",
        "                    temp_3 = {field: getattr(employment_data, field) for field in employment_data._fields if employment_data.ssn == _ssn}\n",
        "                    temp_4 = {field: getattr(update_data, field) for field in update_data._fields if update_data.ssn == _ssn}\n",
        "                    \n",
        "                    # Combine 4 different dictionaries into 1 dictionary\n",
        "                    for data in (temp_1, temp_2, temp_3, temp_4):\n",
        "                        temp.update(data)\n",
        "\n",
        "                    # Convert the data into NamedTuple\n",
        "                    combined_data.append(CombinedData(**temp))\n",
        "\n",
        "                print(len(combined_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGR8R2zFJVwo"
      },
      "source": [
        "# Create an Iterable from Generator to yield the data\n",
        "class DataIterable:\n",
        "    def __init__(self, n):\n",
        "        self._n = n\n",
        "        self._dataset = combined_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._dataset)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return DataIterable.fetch_data(self._n)\n",
        "\n",
        "    @staticmethod\n",
        "    def fetch_data(n):\n",
        "        for i in range(n):\n",
        "            yield combined_data[i]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AfqIt4tKKqP",
        "outputId": "bef2c6af-1233-4408-a1a4-f45e4bbcda89"
      },
      "source": [
        "combined_iterable = DataIterable(5)\n",
        "print(type(combined_iterable))\n",
        "print(f\"Is `combined_iterable` object and Iterable: {isinstance(combined_iterable, Iterable)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.DataIterable'>\n",
            "Is `combined_iterable` object and Iterable: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY8uNxDdNouY",
        "outputId": "0b0a9202-53d0-4cb1-e99e-a00c02aa4dfc"
      },
      "source": [
        "[data for data in combined_iterable]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CombinedData(last_name='Tester', language='Icelandic', employer='Stiedemann-Bailey', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), gender='Male', department='Research and Development', model_year=1993, employee_id='29-0890771', ssn=SSN(AreaNumber='100', GroupNumber='53', SerialNumber='9824'), vehicle_make='Oldsmobile', created=datetime.datetime(2016, 1, 24, 21, 19, 30), first_name='Sebastiano', vehicle_model='Bravada'),\n",
              " CombinedData(last_name='MacDonagh', language='Lao', employer='Nicolas and Sons', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), gender='Female', department='Sales', model_year=1997, employee_id='41-6841359', ssn=SSN(AreaNumber='101', GroupNumber='71', SerialNumber='4702'), vehicle_make='Ford', created=datetime.datetime(2016, 1, 27, 4, 32, 57), first_name='Cayla', vehicle_model='Mustang'),\n",
              " CombinedData(last_name='Lipprose', language='Yiddish', employer='Connelly Group', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), gender='Female', department='Research and Development', model_year=2005, employee_id='98-7952860', ssn=SSN(AreaNumber='101', GroupNumber='84', SerialNumber='0356'), vehicle_make='GMC', created=datetime.datetime(2016, 9, 21, 23, 4, 7), first_name='Nomi', vehicle_model='Yukon'),\n",
              " CombinedData(last_name='Kunzelmann', language='Dhivehi', employer='Upton LLC', last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29), gender='Male', department='Marketing', model_year=2000, employee_id='56-9817552', ssn=SSN(AreaNumber='104', GroupNumber='22', SerialNumber='0928'), vehicle_make='Oldsmobile', created=datetime.datetime(2016, 4, 15, 11, 37, 17), first_name='Justinian', vehicle_model='Intrigue'),\n",
              " CombinedData(last_name='Brixey', language='Afrikaans', employer='Zemlak-Olson', last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33), gender='Male', department='Business Development', model_year=2008, employee_id='46-2886707', ssn=SSN(AreaNumber='104', GroupNumber='84', SerialNumber='7144'), vehicle_make='Ford', created=datetime.datetime(2016, 3, 15, 14, 7, 57), first_name='Claudianus', vehicle_model='Crown Victoria')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUL5bXykQsqG",
        "outputId": "aef6119a-b5e2-46ca-eb02-f489edbf1ff5"
      },
      "source": [
        "[data for data in combined_iterable]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CombinedData(last_name='Tester', language='Icelandic', employer='Stiedemann-Bailey', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), gender='Male', department='Research and Development', model_year=1993, employee_id='29-0890771', ssn=SSN(AreaNumber='100', GroupNumber='53', SerialNumber='9824'), vehicle_make='Oldsmobile', created=datetime.datetime(2016, 1, 24, 21, 19, 30), first_name='Sebastiano', vehicle_model='Bravada'),\n",
              " CombinedData(last_name='MacDonagh', language='Lao', employer='Nicolas and Sons', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), gender='Female', department='Sales', model_year=1997, employee_id='41-6841359', ssn=SSN(AreaNumber='101', GroupNumber='71', SerialNumber='4702'), vehicle_make='Ford', created=datetime.datetime(2016, 1, 27, 4, 32, 57), first_name='Cayla', vehicle_model='Mustang'),\n",
              " CombinedData(last_name='Lipprose', language='Yiddish', employer='Connelly Group', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), gender='Female', department='Research and Development', model_year=2005, employee_id='98-7952860', ssn=SSN(AreaNumber='101', GroupNumber='84', SerialNumber='0356'), vehicle_make='GMC', created=datetime.datetime(2016, 9, 21, 23, 4, 7), first_name='Nomi', vehicle_model='Yukon'),\n",
              " CombinedData(last_name='Kunzelmann', language='Dhivehi', employer='Upton LLC', last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29), gender='Male', department='Marketing', model_year=2000, employee_id='56-9817552', ssn=SSN(AreaNumber='104', GroupNumber='22', SerialNumber='0928'), vehicle_make='Oldsmobile', created=datetime.datetime(2016, 4, 15, 11, 37, 17), first_name='Justinian', vehicle_model='Intrigue'),\n",
              " CombinedData(last_name='Brixey', language='Afrikaans', employer='Zemlak-Olson', last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33), gender='Male', department='Business Development', model_year=2008, employee_id='46-2886707', ssn=SSN(AreaNumber='104', GroupNumber='84', SerialNumber='7144'), vehicle_make='Ford', created=datetime.datetime(2016, 3, 15, 14, 7, 57), first_name='Claudianus', vehicle_model='Crown Victoria')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMHJekNYuN13"
      },
      "source": [
        "---\n",
        "\n",
        "### Goal 3\n",
        "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the last_updated field from the status_update file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCqHg1rdVWbs"
      },
      "source": [
        "total_dataset = DataIterable(len(combined_data))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG9tlwVSuHnd"
      },
      "source": [
        "# List to store the stale records\n",
        "stale_records = []\n",
        "stale_indexes = []\n",
        "stale_threshold = datetime.datetime(2017, 3, 1, 00, 00, 00)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06kDceqHu5ZC",
        "outputId": "e19813f5-7b97-4ff0-df2c-2886b1dc625d"
      },
      "source": [
        "# Filter out all the stale data and stale indexes\n",
        "for index, data in enumerate(total_dataset):\n",
        "    if data.last_updated < stale_threshold:\n",
        "        stale_records.append(data)\n",
        "        stale_indexes.append(index)\n",
        "\n",
        "print(f\"Dataset Size: {len(total_dataset)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Size: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FN0jGYgvec_",
        "outputId": "584551cf-f501-4fe1-a3bf-db051bd0e8ee"
      },
      "source": [
        "# Create current data by removing the stale data from the combined dataset\n",
        "print(f\"Total Stale Records: {len(stale_indexes)}\")\n",
        "\n",
        "current_records = (data for data in total_dataset if data not in stale_records)\n",
        "\n",
        "print(f\"Is current record an Iterator: {isinstance(current_records, Iterator)}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Stale Records: 129\n",
            "Is current record an Iterator: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05R8pXP0yzO2"
      },
      "source": [
        "---\n",
        "\n",
        "### Goal 4\n",
        "Find the largest group of car makes for each gender.\n",
        "\n",
        "Possibly more than one such group per gender exists (equal sizes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xhNYpMNwTn_",
        "outputId": "234925e3-0df3-4beb-d627-4424ab17d7a3"
      },
      "source": [
        "# Largest Group of car for each gender in total dataset\n",
        "vehicle_make_data_male = []\n",
        "vehicle_make_data_female = []\n",
        "\n",
        "for data in total_dataset:\n",
        "    if data.gender == 'Male':\n",
        "        vehicle_make_data_male.append(data.vehicle_make)\n",
        "    elif data.gender == \"Female\":\n",
        "        vehicle_make_data_female.append(data.vehicle_make)\n",
        "\n",
        "male_counter = Counter(vehicle_make_data_male)\n",
        "max_count_vehicle_make_male = max(male_counter.values())\n",
        "largest_group_of_car_for_male = [key for key, value in male_counter.items() if value == max_count_vehicle_make_male]\n",
        "print(f\"Largest Group of Car for Male is {largest_group_of_car_for_male} with a number of {max_count_vehicle_make_male}\")\n",
        "\n",
        "female_counter = Counter(vehicle_make_data_female)\n",
        "max_count_vehicle_make_female = max(female_counter.values())\n",
        "largest_group_of_car_for_female = [key for key, value in female_counter.items() if value == max_count_vehicle_make_female]\n",
        "print(f\"Largest Group of Car for Female is {largest_group_of_car_for_female} with a number of {max_count_vehicle_make_female}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Largest Group of Car for Male is ['Ford'] with a number of 44\n",
            "Largest Group of Car for Female is ['Ford', 'Chevrolet'] with a number of 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2KdV_g96ja2",
        "outputId": "27f56b6e-10ff-49ad-b715-3a33bb420c83"
      },
      "source": [
        "# Largest Group of car for each gender in current dataset\n",
        "vehicle_make_data_male = []\n",
        "vehicle_make_data_female = []\n",
        "\n",
        "for data in current_records:\n",
        "    if data.gender == 'Male':\n",
        "        vehicle_make_data_male.append(data.vehicle_make)\n",
        "    elif data.gender == \"Female\":\n",
        "        vehicle_make_data_female.append(data.vehicle_make)\n",
        "\n",
        "male_counter = Counter(vehicle_make_data_male)\n",
        "max_count_vehicle_make_male = max(male_counter.values())\n",
        "largest_group_of_car_for_male = [key for key, value in male_counter.items() if value == max_count_vehicle_make_male]\n",
        "print(f\"Largest Group of Car for Male is {largest_group_of_car_for_male} with a number of {max_count_vehicle_make_male}\")\n",
        "\n",
        "female_counter = Counter(vehicle_make_data_female)\n",
        "max_count_vehicle_make_female = max(female_counter.values())\n",
        "largest_group_of_car_for_female = [key for key, value in female_counter.items() if value == max_count_vehicle_make_female]\n",
        "print(f\"Largest Group of Car for Female is {largest_group_of_car_for_female} with a number of {max_count_vehicle_make_female}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Largest Group of Car for Male is ['Ford'] with a number of 40\n",
            "Largest Group of Car for Female is ['Chevrolet', 'Ford'] with a number of 42\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}